{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Discussion: Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is an ensemble learning technique where multiple weak learners are combined to form a strong learner. The key principle behind boosting is to sequentially train weak learners and give more weight to the misclassified instances in subsequent iterations, thereby focusing on the difficult-to-classify examples. This iterative process allows boosting algorithms to continuously improve the model's performance.\n",
    "\n",
    "Last week we developed classification decision trees, whereas this week we will focus on regression decision trees. To adapt decision trees for regression we have developed, we need to make some modifications to the traditional classification decision trees.\n",
    "\n",
    "This week's discussion will include several topics:\n",
    "\n",
    "1. Changes to the classification decision tree we developed to make it a regression decision tree.\n",
    "\n",
    "2. For creating a boosted tree learner using regression trees, we employ the AdaBoost algorithm. In each iteration, a regression tree is trained on the residuals (the differences between the actual and predicted values) of the previous iteration. This process continues, with each new tree correcting the errors of the previous ones, ultimately leading to a strong ensemble model.\n",
    "\n",
    "3. To visualize the regression dataset, we plot the input feature against the target variable. Once the model is trained, we will apply it to the data and visualize the output predictions, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This discussion on fitting decision trees is based on the following references:\n",
    "\n",
    "https://github.com/patrickloeber/MLfromscratch/blob/master/mlfromscratch/decision_tree.py\n",
    "\n",
    "https://blog.mlreview.com/gradient-boosting-from-scratch-1e317ae4587d\n",
    "\n",
    "https://www.kaggle.com/code/grroverpr/gradient-boosting-simplified/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Changing the classification decision tree to a regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we constructed a classification decision tree, and this week, we're adapting the same codebase to create a regression decision tree. Surprisingly, most of the existing code can be repurposed, necessitating only two alterations:\n",
    "\n",
    "* Splitting Criteria: While our classification trees relied on entropy for optimal splits, regression trees require a different approach. Typically, we assess splits using metrics such as mean squared error (MSE) or mean absolute error (MAE) to gauge enhancements in prediction accuracy. In our case, we opt for mean squared error.\n",
    "\n",
    "* Leaf Node Prediction: In classification trees, leaf nodes forecast the prevalent class within their domain. Conversely, in regression trees, leaf nodes predict a continuous value, commonly the mean (for MSE) or median (for MAE) of the target values within their domain. In our case, we use MSE to match our splitting criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by briefly reviewing the code we had last week and making adjustments as needed. We'll clearly indicate the sections that need modification and those that remain unchanged. The decision tree implementation provided below is identical to last week's code unless specified otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, we used the `entropy` function below as the splitting criteria. This function measures the entropy in the given labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(y):\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the shift in our objective from classification to regression, we'll no longer utilize the aforementioned function for splitting criteria. Instead, we'll employ the `MSE` function provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def MSE(y):\n",
    "    pred = np.mean(y)\n",
    "    return np.mean((y-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `MSE` outlined above operates on the labels $y$ and performs the following steps:\n",
    "\n",
    "* The prediction pred is computed as the mean of the labels.\n",
    "* Mean squared error (MSE) is then computed by squaring the differences between the labels and the prediction `pred`, then averaging these squared differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The foundational component of our tree structure is the class `Node`, as defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self, feature=None, threshold=None, left=None, right=None, value=None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Node` class `__init__()` function is designed to five arguments:\n",
    "\n",
    "* `feature`: Represents the feature on which the node splits. Applicable to non-leaf nodes.\n",
    "\n",
    "* `threshold`: Denotes the threshold for the node's split. Applicable to non-leaf nodes.\n",
    "\n",
    "* `left`: Refers to the left child of the node. Applicable to non-leaf nodes.\n",
    "\n",
    "* `right`: Denotes the right child of the node. Applicable to non-leaf nodes.\n",
    "\n",
    "*  `value`: Represents the node's value used for prediction. Applicable to leaf nodes.\n",
    "\n",
    "The function `is_leaf_node()` returns `True` if the class attribute `value` is set, indicating that the node is a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct the `DecisionTree` class gradually, one function at a time. To enhance understanding, we'll initially define the functions outside the class and later assemble them within the class structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DecisionTree` class `__init__` function is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth\n",
    "    self.n_feats = n_feats\n",
    "    self.root = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__init__()` function of the `DecisionTree` class, there are three arguments:\n",
    "\n",
    "* `min_samples_split`: Represents the minimum number of samples in a node required for further splitting.\n",
    "\n",
    "* `max_depth`: Denotes the maximum depth allowed for the tree.\n",
    "\n",
    "* `n_feats`: Indicates the number of features present in the dataset.\n",
    "\n",
    "The `root` attribute of the class is initialized to $None$ and will be assigned later during the tree fitting process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `fit` is used for fitting the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y):\n",
    "    self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "    self.root = self._grow_tree(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `fit()` takes in two arguments: input features and the output labels.\n",
    "\n",
    "* Sets the `n_feats` attribute as the number of features.\n",
    "* Calls the `_grow_tree()` function and assigns the output to the `root` attribute. We will see the function `_grow_tree()` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's examine the `_grow_tree()` function provided below. This function closely resembles the one developed for classification, with the exception of line 11, where the leaf value is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grow_tree(self, X, y, depth=0):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_labels = len(np.unique(y))\n",
    "\n",
    "    # stopping criteria\n",
    "    if (\n",
    "        depth >= self.max_depth\n",
    "        or n_labels == 1\n",
    "        or n_samples < self.min_samples_split\n",
    "    ):\n",
    "        leaf_value = self._mean_label(y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "\n",
    "    # greedily select the best split according to information gain\n",
    "    best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "\n",
    "    # grow the children that result from the split\n",
    "    left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "    left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "    right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "    return Node(best_feat, best_thresh, left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_grow_tree()` function takes in 3 inputs:\n",
    "\n",
    "* `X`: Represents the input features of the training data within the node to be split.\n",
    "\n",
    "* `y`: Denotes the labels of the training data within the node to be split.\n",
    "\n",
    "* `depth`: Indicates the depth within the tree. It ensures that the tree is fitted only up to the specified `max_depth`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_grow_tree()` function performs the following tasks:\n",
    "\n",
    "* Line 2 computes the dimensions of the input data.\n",
    "* Line 3 calculates the number of unique labels present in the input data.\n",
    "* Line 6 checks the stopping criteria:\n",
    "  - Line 7: If the depth of the tree has reached `max_depth`.\n",
    "  - Line 8: If there is only one unique label present in the node (i.e., entropy equals 0).\n",
    "  - Line 9: If the number of data points in the node is less than `min_samples_split`.\n",
    "* Line 11: If any of the conditions in the if statement on line 6 evaluates to True:\n",
    "  - We have reached a leaf node.\n",
    "  - The average label in the node is computed and assigned as the leaf label.\n",
    "* Line 14: A subset of features is randomly chosen for splitting. This is particularly useful for random forest where feature selection is randomized at each node.\n",
    "* Line 17: The best split is determined by calling the `_best_criteria` function.\n",
    "* Line 20: The data point indexes that belong to the left and right nodes after the split are computed.\n",
    "* Lines 21 and 22: The `_grow_tree()` function is recursively called on the data in the left and right nodes.\n",
    "* Line 23: The subtrees built in the left and right nodes are used to construct the overall tree, with the current node as the root. The result is then returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll inspect the `_best_criteria()` function, responsible for determining the optimal feature and splitting point. Unlike last week, this function has been modified for regression instead of classification. It now takes the input data and the list of feature indexes designated for splitting in this node as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _best_criteria(self, X, y, feat_idxs):\n",
    "    best_score = -1\n",
    "    split_idx, split_thresh = None, None\n",
    "    for feat_idx in feat_idxs:\n",
    "        X_column = X[:, feat_idx]\n",
    "        thresholds = np.unique(X_column)\n",
    "        for threshold in thresholds:\n",
    "            score = self._split_score(y, X_column, threshold)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                split_idx = feat_idx\n",
    "                split_thresh = threshold\n",
    "\n",
    "    return split_idx, split_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, `_best_criteria()` function executes the following steps:\n",
    "* Line 5: Retrieves the column on which we are evaluating splits and stores it in the variable `X_column`. \n",
    "* Line 6: Computes all the unique values present in `X_column`, which will serve as our splitting thresholds.\n",
    "* Line 7: In a loop over different thresholds:\n",
    "  - Line 8: Calculates the score as the split score by calling the `_split_score()` function.\n",
    "  - Line 9: If the score gain is greater than the best score observed so far, updates the current gain as the best gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine the `_split_score()` function. This function accepts the data labels `y`, the column we are evaluating for splitting `X_column`, and the threshold under consideration `split_thresh`. Its purpose is to compute the split score if we were to choose that split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_score(self, y, X_column, split_thresh):\n",
    "    # parent MSE\n",
    "    parent_score = MSE(y)\n",
    "\n",
    "    # generate split\n",
    "    left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
    "\n",
    "    if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "        return 0\n",
    "\n",
    "    # compute the weighted avg. of the MSE scores for the children\n",
    "    n = len(y)\n",
    "    n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "    s_l, s_r = MSE(y[left_idxs]), MSE(y[right_idxs])\n",
    "    child_score = (n_l / n) * s_l + (n_r / n) * s_r\n",
    "\n",
    "    # split score is difference in MSE before vs. after split\n",
    "    ig = parent_score - child_score\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, `_split_score()` function executes the following steps:\n",
    "* Line 3: Computes the MSE in the parent.\n",
    "* Line 6: Calculates the indexes of data points in the left and right nodes if the split under consideration is implemented.\n",
    "* Line 8: Returns 0 if either child node ends up without any data points after the split.\n",
    "* Lines 12 to 15: Computes the weighted average of child MSE's.\n",
    "* Line 19: Returns the difference between the parent MSE and the child MSE's as the split score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's direct our attention to the `_split()` function, which determines the distribution of data samples into the right or left child nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split(self, X_column, split_thresh):\n",
    "    left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "    right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "    return left_idxs, right_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_split()` function takes in the column we are evaluating for splitting, as well as the threshold. It identifies the indexes where the value in `X_column` is less than or equal to or greater than the `split_thresh`, and returns them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the leaf weight, we utilize the `_mean_label()` function to compute the mean value in the labels. Let's delve into how this function operates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_label(self, y):\n",
    "    return np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function simply takes the average of all labels in `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've completed the functions responsible for fitting the tree. Finally, let's explore how we perform predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "def _traverse_tree(self, x, node):\n",
    "    if node.is_leaf_node():\n",
    "        return node.value\n",
    "\n",
    "    if x[node.feature] <= node.threshold:\n",
    "        return self._traverse_tree(x, node.left)\n",
    "    return self._traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During prediction, we invoke the `predict()` function, which accepts the testing data. As shown in line 2, it iterates through all the data points in the test data `X`, calling the `_traverse_tree()` function.\n",
    "\n",
    "The `_traverse_tree()` function, defined on line 4, is a recursive function that takes a single test data point and the current node (initially the root). If the current node is a leaf node, it returns the value of the leaf node as the prediction. If not, based on the splitting criteria of that node, it recursively calls the `_traverse_tree()` function on either the left or the right child node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all we developed together in a single class, we will have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def MSE(y):\n",
    "    pred = np.mean(y)\n",
    "    return np.mean((y-pred)**2)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self, feature=None, threshold=None, left=None, right=None, *, value=None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X]).reshape(-1, 1)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # stopping criteria\n",
    "        if (\n",
    "            depth >= self.max_depth\n",
    "            or n_labels == 1\n",
    "            or n_samples < self.min_samples_split\n",
    "        ):\n",
    "            leaf_value = self._mean_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        feat_idxs = np.random.choice(n_features, self.n_feats, replace=False)\n",
    "\n",
    "        # greedily select the best split according to information gain\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, feat_idxs)\n",
    "\n",
    "        # grow the children that result from the split\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth + 1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth + 1)\n",
    "        return Node(best_feat, best_thresh, left, right)\n",
    "\n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        best_score = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                score = self._split_score(y, X_column, threshold)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _split_score(self, y, X_column, split_thresh):\n",
    "        # parent MSE\n",
    "        parent_score = MSE(y)\n",
    "\n",
    "        # generate split\n",
    "        left_idxs, right_idxs = self._split(X_column, split_thresh)\n",
    "\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute the weighted avg. of the MSE scores for the children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        s_l, s_r = MSE(y[left_idxs]), MSE(y[right_idxs])\n",
    "        child_score = (n_l / n) * s_l + (n_r / n) * s_r\n",
    "\n",
    "        # split score is difference in MSE before vs. after split\n",
    "        ig = parent_score - child_score\n",
    "        return ig\n",
    "\n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n",
    "    def _mean_label(self, y):\n",
    "        return np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting is an ensemble method where predictors are not created independently but rather sequentially. This approach involves subsequent predictors learning from the errors of previous ones. Consequently, observations are weighted unequally in subsequent models, with those exhibiting higher errors being prioritized. Unlike the bootstrap process, observations are selected based on error. Predictors can encompass various models such as decision trees, regressors, or classifiers. Due to new predictors learning from past mistakes, fewer iterations are needed to approximate actual predictions. However, careful selection of stopping criteria is essential to avoid overfitting on training data. Gradient Boosting serves as a prominent example of a boosting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of every supervised learning algorithm is to establish a loss function and then minimize it. Now, let's explore the mathematical workings of the Gradient Boosting algorithm. Our chosen loss function is the mean squared error (MSE):\n",
    "\n",
    "$$\n",
    "MSE = \\sum{{(\\hat{y}_i - y_i)}^2},\n",
    "$$\n",
    "where $y_i$ is the label of the i'th datapoint and $\\hat{y}_i$ is the predicted label for the i'th datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize gradient descent in our gradient boosting scheme, we must first determine the gradient. The gradient of the expression above with respect to $\\hat{y}_i$ can be easily derived as:\n",
    "$$\n",
    "\\frac{\\partial \\sum{{(\\hat{y}_i - y_i)}^2}}{\\partial \\hat{y}_i} = 2 \\sum{{(\\hat{y}_i - y_i)}}\n",
    "$$\n",
    "Thus, moving in the opposite direction of the gradient will lead us to the updates:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\hat{y}_i - \\eta * 2 * \\sum{{(\\hat{y}_i - y_i)}},\n",
    "$$\n",
    "where $\\eta$ denotes the learning rate.\n",
    "\n",
    "For enhanced simplicity in the formula, we combine 2 into $\\eta$, resulting in the formula:\n",
    "$$\n",
    "\\hat{y}_i = \\hat{y}_i - \\eta * \\sum{{(\\hat{y}_i - y_i)}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, in a training loop where each iteration entails adding a tree to the existing ensemble, we incorporate a tree that is fitted to the error as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initiate the creation of the gradient boosting class. We begin by the class constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, n_estimators = 100, eta = 0.1, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth         = max_depth\n",
    "    self.n_feats           = n_feats\n",
    "\n",
    "    self.n_estimators      = n_estimators\n",
    "    self.eta               = eta\n",
    "    self.y0                = None\n",
    "    self.trees             = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__init__()` function provided above, you may recognize lines 2 through 4 as the hyperparameters for our regression trees. The remaining lines are as follows:\n",
    "\n",
    "* Line 6: Sets `n_estimators` as the number of trees in the ensemble.\n",
    "* Line 7: Defines the learning rate $\\eta$ as explained previously.\n",
    "* Line 8: Initializes $y_0$. This value represents the constant prediction used before fitting any trees and is simply the average of all input labels.\n",
    "* Line 9: Initializes the list of trees to be fitted as an empty list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us focus on the `fit()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y):\n",
    "    self.y0 = np.mean(y)\n",
    "    error   = self.y0 - y\n",
    "    for _ in range(self.n_estimators):\n",
    "        new_tree = DecisionTree(max_depth=self.max_depth, min_samples_split = self.min_samples_split, n_feats = self.n_feats)\n",
    "        new_tree.fit(X, error)\n",
    "        self.trees.append(new_tree)\n",
    "        error =  self.predict(X) - y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` function described above performs the following tasks:\n",
    "\n",
    "* Line 2: Computes `self.y0` as a constant prediction, representing the mean of training data labels before any trees are fitted.\n",
    "* Line 3: Calculates the error in prediction, which equals the current prediction `self.y0` minus the labels. This identifies the deviation for any sample in the dataset if we predict the constant mean value.\n",
    "* Line 4: Initializes a loop that iterates `self.n_estimators` times, fitting a new tree at each iteration.\n",
    "* Line 5: Initializes a new tree with the provided hyperparameters.\n",
    "* Line 6: Fits the new tree to the error computed as the label.\n",
    "* Line 7: Appends the newly acquired tree to the list of trees.\n",
    "* Line 8: Computes the error for the next iteration. This error is calculated as the current output of the ensemble we have built so far minus the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the `predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    return self.y0 - self.eta * sum([tree.predict(X) for tree in self.trees])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function accepts input features and predicts the output as the constant prediction `self.y0` minus the sum of the predictions of the trees, multiplied by the learning rate $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_booster:\n",
    "    def __init__(self, n_estimators = 100, eta = 0.1, min_samples_split=2, max_depth=100, n_feats=None):\n",
    "        self.n_estimators      = n_estimators\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth         = max_depth\n",
    "        self.n_feats           = n_feats\n",
    "        self.eta               = eta\n",
    "        self.y0                = None\n",
    "        self.trees             = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.y0 = np.mean(y)\n",
    "        error   = self.y0 - y\n",
    "        for _ in range(self.n_estimators):\n",
    "            new_tree = DecisionTree(max_depth=self.max_depth, min_samples_split = self.min_samples_split, n_feats = self.n_feats)\n",
    "            new_tree.fit(X, error)\n",
    "            self.trees.append(new_tree)\n",
    "            error =  self.predict(X) - y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.y0 - self.eta * sum([tree.predict(X) for tree in self.trees])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a dataset for our regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple regression dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,50).reshape(-1, 1)\n",
    "\n",
    "# just random uniform distributions in differnt ranges\n",
    "y1 = np.random.uniform(10,15,10)\n",
    "y2 = np.random.uniform(20,25,10)\n",
    "y3 = np.random.uniform(0,5,10)\n",
    "y4 = np.random.uniform(30,32,10)\n",
    "y5 = np.random.uniform(13,17,10)\n",
    "\n",
    "# concatenating all of them together\n",
    "y = np.concatenate((y1,y2,y3,y4,y5)).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data we've created, let's draft a simple plot function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(x, y, preds = None):\n",
    "    fig, ax  = plt.subplots()\n",
    "    ax.scatter(x, y, color = 'k')\n",
    "    if not preds is None:\n",
    "        ax.plot(x, preds, color = 'red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we craeted looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAueklEQVR4nO3df3AUdZ7/8VczSPwBCYuEJNADg64rqxZcHatsyhsvOTjR27KC46gL/oGu5ZZsuErEvbtlr1aw6rawtI5KvGJ1q65Oruo2wTMZpNwtqVOcgayH7opS6nlS4oUjxATY9ZggLlGG/v7hd2YZ8mN6oOcz05Pno2qqnO6m+5M2Rb/4fN6fT1uO4zgCAAAwZFKxGwAAACYWwgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAoyYXuwHnO3v2rD755BNNmzZNlmUVuzkAAMAFx3F08uRJzZ49W5Mmjd+3UXLh45NPPlEwGCx2MwAAwAXo6+uTbdvjHlNy4WPatGmSvmp8ZWVlkVsDAADcGBoaUjAYzDzHx1Ny4SM91FJZWUn4AADAZ9yUTFBwCgAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCq5BYZA4BSl0ql1NPTo4GBAdXV1SkcDisQCBS7WYBvED4AIA+xWEwtLS06cuRIZptt22pvb1ckEiliywD/YNgFAFyKxWKKRqNZwUOS+vv7FY1GFYvFitQys1KplBKJhDo7O5VIJJRKpYrdJPiM5TiOU+xGnGtoaEhVVVVKJpO82wVAyUilUgqFQiOCR5plWbJtW729va6HYPw4fEPPD8aSz/Obng8AcKGnp2fM4CFJjuOor69PPT09rs4Xi8UUCoXU2NioVatWqbGxUaFQaNTek1LpaaDnB14hfACACwMDA54dl89DPJ+Q4oWxgk4qlVJLS4tG6yxPb2ttbc0KRqUSmlCCnBKTTCYdSU4ymSx2UwAgIx6PO5JyfuLx+LjnOXPmjGPb9ph/3rIsJxgMOmfOnHG6u7sdy7JGPcayLKe7u9vTn7G7u3tE22zbdrq7u/P++cc7F8pTPs9vaj4AwIV0zUd/f/+o//p3W/ORSCTU2NiY83qvvvqq7r//fk9rTMaT7o05/2ezLEuS1NLSora2tpzn6ejoUEVFxbjn6urqoj6kDFHzAQAeCwQCam9vl/THh2ha+ntbW1vOIOB2+CaRSHhaYzIeN0Mqv/jFL1yda9asWXkPz2DiIXwAgEuRSERdXV2aM2dO1nbbtl3/a76urs7TNrkNM+NxU0x7/PhxVVdXjwheaZZlKRgMSlJeoYm6kImJ8AEAeYhEIjp06JDi8bg6OjoUj8fV29vrehghHA7Ltu2cD/GGhgZX5/MizLgNMPfdd5+k8Xt+jh075vqapotpUToIHwCQp0AgoIaGBq1cuVINDQ151Vy4Hb5paGhwFVLC4fAF/hR/5DbANDU15ez5cXuujz76iGm7ExgFpwBQBKMt1hUMBtXW1pbpRUkXgUrKqqHwunAz32La8RZHc3OudHgxVUwLM/J5fhM+AKBI3Kxw6iakeMHLoJPrXBs3btSGDRtynicej7sefkLxET4AoMi8XDrd1DLsXgad8c41PDysVatW5TxHR0eHVq5cmdd1UTyEDwAoIj+//8REaHK71gk9H/5C+ACAIsm1WBcLbHm3YBtKC4uMAUARXMj7T7y8dq71MkplTQ2vFmyDf+UVPp555hktXLhQlZWVqqysVH19vV5++eXM/tOnT6u5uVlXXnmlpk6dqrvuuktHjx71vNEAUIq8fvOtW27Wyyi1NTW8WLAN/pXXsMtLL72kQCCga665Ro7j6F//9V/11FNP6Z133tH111+vNWvW6Fe/+pW2bt2qqqoqrV27VpMmTdLrr7/uukEMuwDwq87OTuOFlG6GeSSV7FCQqWJaFJ7Rmo8ZM2boqaeeUjQaVXV1tTo6OjJTrD788EN985vf1N69e/Xtb3/b88YDQCkxXUiZrp0Yb70M1tSAKUZqPlKplLZt26ZTp06pvr5e+/bt05dffqlly5ZljlmwYIHmzp2rvXv3jnme4eFhDQ0NZX0AwI/cLp3uxaqkkrthniNHjhRlKAgYT97h47333tPUqVNVUVGhhx9+WNu3b9d1112nwcFBTZkyRdOnT886vqamRoODg2Oeb9OmTaqqqsp80i8mAgC/MV1I6cVL5QpxLiCXvMPHtddeq/379+vNN9/UmjVrtHr1an3wwQcX3ID169crmUxmPn19fRd8LgAoNpOFlF6+Idfrt+0C47nomo9ly5bp6quv1r333qulS5fq//7v/7J6P+bNm6fW1lY98sgjrs5HzQeAcmCikDKf96iwpgYKLZ/n9+SLvdjZs2c1PDysxYsX65JLLtGuXbt01113SZIOHDigw4cPq76+/mIvAwC+kn7zbaGv0d7ermg0KsuyRn2PSnoYaLxjWFMDpuU17LJ+/Xrt2bNHhw4d0nvvvaf169crkUjovvvuU1VVlR588EGtW7dO8Xhc+/bt0wMPPKD6+nrXM10AAPlxM8zDmhooNXkNuzz44IPatWuXBgYGVFVVpYULF+rv/u7v9Jd/+ZeSvlpk7NFHH1VnZ6eGh4e1fPly/exnP1Ntba3rBjHsAgD5czPMw5oaKCTe7QIAAIzi3S4AAKBkET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYFRe4WPTpk268cYbNW3aNM2aNUsrVqzQgQMHso5paGiQZVlZn4cfftjTRgMAAP/KK3zs3r1bzc3NeuONN/TKK6/oyy+/1K233qpTp05lHffQQw9pYGAg83nyySc9bTQAAPCvyfkcvHPnzqzvW7du1axZs7Rv3z7dcsstme2XX365amtrvWkhylYqlVJPT48GBgZUV1encDisQCBQ7GYBAArsomo+ksmkJGnGjBlZ23/xi19o5syZuuGGG7R+/Xp9/vnnY55jeHhYQ0NDWR/4XyqVUiKRUGdnpxKJhFKpVNb+WCymUCikxsZGrVq1So2NjQqFQorFYkVqcenKdS8BwHecC5RKpZzvfOc7zs0335y1/ec//7mzc+dO591333X+7d/+zZkzZ45z5513jnmeDRs2OJJGfJLJ5IU2DUXW3d3t2Lad9f/Ttm2nu7s7s9+yrBH/zy3LcizLyhyH3PcSAEpFMpl0/fy2HMdxLiS0rFmzRi+//LJ+/etfy7btMY977bXXtHTpUh08eFBXX331iP3Dw8MaHh7OfB8aGlIwGFQymVRlZeWFNA1FFIvFFI1Gdf6vlWVZkqTnn39e69at05EjR0b985ZlybZt9fb2TvghmFz3squrS5FIpBhNA4ARhoaGVFVV5er5fUHhY+3atdqxY4f27Nmj+fPnj3vsqVOnNHXqVO3cuVPLly/Pee58Go/SkkqlFAqFxg0WM2fO1PHjx3OeKx6Pq6GhweMW+oebe0lIA1BK8nl+51Xz4TiO1q5dq+3bt+u1117LGTwkaf/+/ZKkurq6fC4FH+rp6RnzYSl99fvjJnhI0sDAgFfN8iU397Kvr089PT0GWwUA3shrtktzc7M6Ojq0Y8cOTZs2TYODg5KkqqoqXXbZZfr444/V0dGhv/qrv9KVV16pd999V4888ohuueUWLVy4sCA/AEqHl4FhoodVt/dyooc0AP6UV8/HM888o2QyqYaGBtXV1WU+zz//vCRpypQpevXVV3XrrbdqwYIFevTRR3XXXXfppZdeKkjjUVrcBobq6upM3cL5LMtSMBhUOBz2smm+4/ZeTvSQBsCfLrjgtFCo+fCvdJ1Cf3//iCJJ6Y91Cps3b9Y999wjSVnHUUj5R27vJTUfAEpFwWo+gPEEAgG1t7dL0oiejfT3trY2RaNRdXV1ac6cOVnH2LZN8Pj/3N5LggcAP6LnA56LxWJqaWnJKpgMBoNqa2vLChascJqb23sJAMVW8Km2hUT4KA8EC+9wLwH4AeEDAAAYRc0HAAAoWYQPAABgFOEDAAAYRfgAAABG5bW8OgB3mKECAGMjfAAeG21tDtu21d7eztocACCGXQBPxWIxRaPREW+k7e/vVzQaVSwWK1LLAKB0ED4Aj6RSKbW0tIz6Lpb0ttbWVqVSKdNNA4CSQvgAPNLT0zOix+NcjuOor69PPT09BlsFAKWH8AF4ZGBgwNPjAKBcET4Aj9TV1Xl6HACUK8IH4JFwOCzbtjOvvD+fZVkKBoMKh8OGWwYApYXwAXgkEAiovb1dkkYEkPT3trY21vsAMOERPgAPRSIRdXV1ac6cOVnbbdtWV1cX63wAgCTLGW1eYBHl80peoFSxwimAiSaf5zcrnAIFEAgE1NDQUOxmAEBJYtgFAAAYRfgAAABGET4AAIBRhA8AAGAUBadAETErBsBERPgAiiQWi6mlpSXrZXS2bau9vZ31QACUNYZdMGGkUiklEgl1dnYqkUgU9dX2sVhM0Wh0xFtw+/v7FY1GFYvFitQyACg8wgcmhFgsplAopMbGRq1atUqNjY0KhUJFecinUim1tLRotPX90ttaW1uLGo4AoJAIHyhpXvRW5NPLYKJ3pKenZ0RbzuU4jvr6+tTT0+P5tQGgFBA+ULK86K3Ip5fBVO/IwMCAp8cBgN8QPlCSvKqJcNvL8NOf/tRYDUZdXZ2nxwGA3/BiOZScVCqlUCg0ZmiwLEu2bau3tzfntNTOzk6tWrUq5zVnzJihTz/99KKv50b65+vv7x+1R8br6wGACfk8v+n5QMm5kJqIsWo13PYejBU8xrrexQgEAmpvb5f0VdA4V/p7W1sbwQNA2SJ8oOTkWxMxXq1GOByWbdsjHvJplmVpxowZnrbLjUgkoq6uLs2ZMydru23b6urqYp0PAGWNYReUnEQiocbGxpzHxeNxffrpp4pGoyOGL9Jho6urS5IUjUYlKeu49DEbN27Uhg0bXF2voaHB01VJWeEUQLnI5/lN+EDJcVsTcfDgQV199dWuakN27NgxYjXRYDCotrY2NTU1ua7BGO08rEoKAIQPlIH0bBdp9N6Krq4uzZgxw3UPSa4eCzfXk5Szl4UAAmCiouAUvuemJiLf2pBAIKCGhgatXLlSDQ0NWcMbua7X1NTEqqQA4BFeLIeSFYlE1NTUNGZvhdfrZYx3vUQi4XoGTkNDg6vrAcBERfhASUv3VowmPZMlV61GOBy+6OuxKikAeIdhF/iWyfUyWJUUALxD+ICvmVovw816IcFgMK9eFgCYqJjtgrJgYr0MNzNimO0CYKIq2GyXTZs26cYbb9S0adM0a9YsrVixQgcOHMg65vTp02pubtaVV16pqVOn6q677tLRo0fz/ymAPIw3k8UrrEoKAN7Iq+fjtttu03e/+13deOONOnPmjH784x/r/fff1wcffKArrrhCkrRmzRr96le/0tatW1VVVaW1a9dq0qRJev31111dg54PlDpWJQWAkYwtMnb8+HHNmjVLu3fv1i233KJkMqnq6mp1dHRkuqc//PBDffOb39TevXv17W9/29PGAwCA0mBskbFkMilJmRdz7du3T19++aWWLVuWOWbBggWaO3eu9u7dO+o5hoeHNTQ0lPUBAADl64LDx9mzZ9Xa2qqbb75ZN9xwgyRpcHBQU6ZM0fTp07OOramp0eDg4Kjn2bRpk6qqqjKfYDB4oU0CAAA+cMHho7m5We+//762bdt2UQ1Yv369kslk5tPX13dR5wMAAKXtglY4Xbt2rX75y19qz549sm07s722tlZffPGFTpw4kdX7cfToUdXW1o56roqKClVUVFxIMwAAgA/l1fPhOI7Wrl2r7du367XXXtP8+fOz9i9evFiXXHKJdu3aldl24MABHT58WPX19d60GAAA+FpePR/Nzc3q6OjQjh07NG3atEwdR1VVlS677DJVVVXpwQcf1Lp16zRjxgxVVlbqr//6r1VfX+9qpgsAACh/eU21HWtp6eeee07333+/pK8WGXv00UfV2dmp4eFhLV++XD/72c/GHHY5H1NtAQDwH2PrfBQC4QMAAP8xts4HAABAvggfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwCjCBwAAMIrwAQAAjJpc7AYAAAAzUqmUenp6NDAwoLq6OoXDYQUCAePtIHwAADABxGIxtbS06MiRI5lttm2rvb1dkUjEaFsYdgEAoMzFYjFFo9Gs4CFJ/f39ikajisViRttD+AAAoIylUim1tLTIcZwR+9LbWltblUqljLWJ8AEAQBnr6ekZ0eNxLsdx1NfXp56eHmNtInwAAFDGBgYGPD3OC4QPAADKWF1dnafHeYHwAQBAGQuHw7JtW5ZljbrfsiwFg0GFw2FjbSJ8AABQxgKBgNrb2yVpRABJf29razO63gfhAwDge6lUSolEQp2dnUokEkZnbvhBJBJRV1eX5syZk7Xdtm11dXUZX+fDckabe1NEQ0NDqqqqUjKZVGVlZbGbAwAocW4XzyqV1T2LqZD3IJ/nN+EDAOBb6cWzzn+UpYcT0v+q93p1T4LMSIQPAEDZS6VSCoVCY65hYVmWbNvW5s2bdc899+QMKG6V0jLlpYTwAQAoe4lEQo2NjTmPq66u1vHjx0fdlw4ovb29mZ6L8Xo13Pa0TET5PL8pOAUA+JLbRbHGCh7SyNU9Y7GYQqGQGhsbtWrVKjU2NioUCikWi5XkMuV+RfgAAPiSl4tiDQwM5Hz52k9/+tOSW6bcrwgfAABfcrN4VnV1tatzzZo1K2evRnqtjFxMLlPuV4QPAIAvuVk8a8uWLa5W95SUs1fj008/ddUuk8uU+xXhAwDgW7kWz7r77rtdre557NgxV9ebMWNGSS1T7ld5h489e/bojjvu0OzZs2VZll588cWs/ffff78sy8r63HbbbV61FwCALJFIRIcOHVI8HldHR4fi8bh6e3szs07crO7ptreipaVFUuksU+5Xk/P9A6dOndKiRYv0ve99b8zpRLfddpuee+65zPeKiooLbyEAADkEAgE1NDSMuT8SiaipqWnMKbTp+pH+/v5R6z7SU3L//u//XjfccMOo63y0tbXlPc12oi5Wlnf4uP3223X77bePe0xFRYVqa2svuFEAAHhtvICSrh+JRqOyLCsrgJzfq5EryLg1kRcrK0jNRyKR0KxZs3TttddqzZo1+v3vfz/mscPDwxoaGsr6AABgWj4vX0sHmZUrV6qhoWHU4DHey+5yTeuNxWIe/3Sl5aJWOLUsS9u3b9eKFSsy27Zt26bLL79c8+fP18cff6wf//jHmjp1qvbu3Tvq/5yNGzfq8ccfH7GdFU4BAJL5oQkvrjder0ZTU5OrZeHPXXXVD4wtrz5a+Djf//zP/+jqq6/Wq6++qqVLl47YPzw8rOHh4azGB4NBz8PHRB1XAwA/8+PQRK4l2Ddu3KgNGzbkPE88Hh+3jqXUlNTy6ldddZVmzpypgwcPjrq/oqJClZWVWR+vjbdcLgCgNPlxaMLNEuwsVmYgfBw5ckS///3vi7boite/vOON4QEAvOHX96j09PSwWJkLeYePzz77TPv379f+/fslSb29vdq/f78OHz6szz77TH/zN3+jN954Q4cOHdKuXbvU1NSkr3/961q+fLnXbc/J619etz0oBBQAuDhuHuKl+B4Vt70V+SxWVpbPFCdP8XjckTTis3r1aufzzz93br31Vqe6utq55JJLnHnz5jkPPfSQMzg46Pr8yWTSkeQkk8l8m+a6red/4vF4znN1d3c7lmWN+LOWZTmWZTnd3d2Z42zbzjrGtu3MfgBAbh0dHa7+/u7o6Ch2U7O4fe48/vjjmedHuTxT8nl+5x0+Cs3L8OHVL++ZM2dG/M8//5clGAw6L7zwgquAAgAYn5f/eDQp/bwY7Vlw7vPizJkzowaLYDCYFTz89EzJ5/l9UbNdCiGfatlcEomEGhsbcx6Xq6LY7Xmqq6t1/PjxUff5deoUABRDKpVSKBTKueJoKf6dmq41lDTqYmXnrhky1kzM9M/vp+m4JTXbpZjcvG7ZzUuA3I7hjRU8pNIdnwSAUuTmjbWl+h4VLxYr82vNi1tlHT68+uX1suK4nKdOAYCX8nmIl5pcL7vLxe2zwq/PlLzf7eI36V/ei3kJkJsXDs2cOXPcno+0cp46BQBe8+o9KsWQ62V343H7rPDrM6Wsaz7OdbErnOYaw3v++ee1bt06X45PAgBKix9rXqj5GIWblwCNJ1f339133+3b8UkAQGnxc82LGxOm58MruXpQRnsPQTAYdD3EAwBAmp+eKcZeLFcIpR4+3OAldgAAr/jlmUL4AABggil2SMnn+V32s10AACh3ow3P2Lat9vb2khuekSZQwSkAAOXI67e3m0D4AADAp7x+e7sphA8AAHzKr8uwU/OBLMUuWAIAuOfXZdgJH8jwW8ESAEx0fl2GnWEXSPJnwRIATHRevb3dNMIHfFuwBAATnV+XYSd8lLhUKqVEIqHOzk4lEomCBAC/FiwBAHK/e6wUh82p+Shhpmow/FqwBAD4SiQSUVNTk28mDBA+SlS6BuP8oZB0DYaXadavBUsAgD9Kv73dD3i3SwlKpVIKhUJjDoVYliXbttXb2+tJqk1fr7+/f9S6D6+vBwAoP/k8v6n5OIeJ+go3TNdg+LVgCQDgT4SP/y8WiykUCqmxsVGrVq1SY2OjQqFQUaaYFqMGw48FSwAAf6LmQ2brK9woVg2G3wqWAAD+NOFrPkzXV+TTJmowAAB+Qc1HHkpxjYt8azBKpVYFAAA3Jnz4KNU1LtzWYJRSrQoAAG5M+JqPUl7jIlcNRqnVqgAA4AY1Hz6tryjFWhUAwMRFzUce/LrGRSnWqgAA4MaEDx+SP9e4KNVaFQAAcpnwNR9pflvjIt9alVQq5ZufDQBQ3iZ8zYdf5VOrsmPHDiNvxwUATFzUfEwAbmtVduzYoWg0OqI+JD0jhim5AADTCB9FdLGLg+WqVWlqalJLS8uoPSPpba2trSxKBgAwimGXIonFYp4NhYxVz5FIJNTY2Jjzz8fjcTU0NOT7IwAAkJHP85uC0yLwenGwQCAwanhgRgwAoBQx7GJYKpUyNhRSqNVbeZcMAOBiED4MM7k4WDgclm3bIwpS0yzLUjAYVDgcdn1O3iUDALhYhA/DTA6FeL16a3q4iJkzAICLQfgwzPSL7LxavdXkcBEAoLwx28WwYr3I7mJXOGXmDABgPMx2KWHpoZBoNCrLsrICSCFfZDfWjBi3mDkDAPBK3sMue/bs0R133KHZs2fLsiy9+OKLWfsdx9Fjjz2muro6XXbZZVq2bJk++ugjr9pbFvz4IjvTw0UAgPKVd/g4deqUFi1apC1btoy6/8knn9TTTz+tZ599Vm+++aauuOIKLV++XKdPn77oxpaTSCSiQ4cOKR6Pq6OjQ/F4XL29vSUZPKTCzJwBAExMF1XzYVmWtm/frhUrVkj6qtdj9uzZevTRR/XDH/5QkpRMJlVTU6OtW7fqu9/9bs5zlnvNh5+lZ7tIGnW4qFR7bQAAhVe0F8v19vZqcHBQy5Yty2yrqqrSkiVLtHfv3lH/zPDwsIaGhrI+KE1+HC4CAJQeTwtOBwcHJUk1NTVZ22tqajL7zrdp0yY9/vjjXjYDBRSJRNTU1HRRM2cAABNb0We7rF+/XuvWrct8HxoaUjAYLGKLkMvFzpwBAExsng671NbWSpKOHj2atf3o0aOZfeerqKhQZWVl1gcAAJQvT8PH/PnzVVtbq127dmW2DQ0N6c0331R9fb2XlwIAAD6V97DLZ599poMHD2a+9/b2av/+/ZoxY4bmzp2r1tZW/cM//IOuueYazZ8/Xz/5yU80e/bszIwYAAAwseUdPt56662sZbbT9RqrV6/W1q1b9bd/+7c6deqUvv/97+vEiRP6sz/7M+3cuVOXXnqpd60GAAC+xbtdAADARSvaOh8AAAC5ED4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABhF+AAAAEYRPgAAgFGEDwAAYJTn4WPjxo2yLCvrs2DBAq8vAwAAfGpyIU56/fXX69VXX/3jRSYX5DIAAMCHCpIKJk+erNra2kKcGgAA+FxBaj4++ugjzZ49W1dddZXuu+8+HT58eMxjh4eHNTQ0lPUBAADly/PwsWTJEm3dulU7d+7UM888o97eXoXDYZ08eXLU4zdt2qSqqqrMJxgMet0kAABQQizHcZxCXuDEiROaN2+eNm/erAcffHDE/uHhYQ0PD2e+Dw0NKRgMKplMqrKyspBNAwAAHhkaGlJVVZWr53fBK0GnT5+ub3zjGzp48OCo+ysqKlRRUVHoZgAoY6lUSj09PRoYGFBdXZ3C4bACgUCxmwVgDAVf5+Ozzz7Txx9/rLq6ukJfCsAEFIvFFAqF1NjYqFWrVqmxsVGhUEixWKzYTQMwBs/Dxw9/+EPt3r1bhw4d0n/+53/qzjvvVCAQ0MqVK72+FIAJLhaLKRqN6siRI1nb+/v7FY1GCSBAifI8fBw5ckQrV67Utddeq3vuuUdXXnml3njjDVVXV3t9KQATWCqVUktLi0YrW0tva21tVSqVMt00ADl4XvOxbds2r08JIIeJWPPQ09MzosfjXI7jqK+vTz09PWpoaDDXMAA5sfQo4HOxWEwtLS1ZD2LbttXe3q5IJJLXufwUYgYGBjw9DoA5vFgO8DEvax78VrjptoidYneg9BR8nY985TNPGJjIUqmUQqHQmEMPlmXJtm319vbm7L1Ih5jz/zqwLEuS1NXVlXcvSqGlf/7+/v5R6z5G+/n91LMD+E0+z296PgCfyqfmYTx+LdwMBAJqb2+X9MeQlJb+3tbWlgkXfuvZAcoZ4QPwKa9qHrwKMcUQiUTU1dWlOXPmZG23bTurt4YpuUBpoeAU8Kl8ax7GGnLwe+FmJBJRU1PTmMMpuXp2LMtSa2urmpqaGIIBDCF8AD4VDodl23bOmodwODzujJhSL9x0U6cRCATGnE7LlFyg9DDsAviU25qHHTt2jDvkcPz4cdm2PeIc554rGAwqHA4X4KcYnxd1Gvn27KRSKSUSCXV2diqRSJRcrQtQFpwSk0wmHUlOMpksdlMAX+ju7nZs23YkZT7BYNDp7u52zpw5M2LfuR/LspxgMOi88MILjmVZjmVZI/ZbluV0d3cX5ec6vz0X0qZ4PD7mz3/uJx6Pj3ovbdsuys8P+E0+z2+m2gJlYKyhiUQiocbGxpx/Ph6P69NPPx0xNBMMBtXW1mZ8mq2X04jdTsndvHmz7rnnHl9NNwZKST7Pb2o+gDIwVs1DPkMOK1euHLdw0yQv6zTSw1PRaFSWZWWFi3Sw+Md//Ec98sgjFKUChlDzAZSxfItJ0yFm5cqVamhoKNqD1usZOLmm5FZXV/t2ujHgR/R8AGUsnxkxpaQQM3DGm5Lb2dnp6hylOt0Y8BvCB1DG3Aw5nLsKaKkoVGgaa3iq1KcbA+WGYRegzLldBbSU5Lt0+sVKh51SnG4MlCPCBzABRCIRHTp0SPF4XB0dHYrH4+rt7S3J4JFmMjSZDjvARMdUWwAlzeSbaEdbCbZY040Bv8nn+U34AIBzmAw7QDlhnQ8AuEDjvScGgDeo+QAAAEYRPgAAgFGEDwAAYBThAwAAGEX4AAAARhE+AACAUYQPAABgFOEDAAAYRfgAAABGET4AAIBRhA8AAGAU4QMAABjFi+UAFA1vkAUmJsIHgKKIxWJqaWnRkSNHMtts21Z7e7sikUgRWwag0Bh2AWBcLBZTNBrNCh6S1N/fr2g0qlgsVqSWATCB8AHAqFQqpZaWFjmOM2Jfeltra6tSqZTppgEwhPABwKienp4RPR7nchxHfX196unpMdgqACZR8wEgbxdTKDowMODpcQD8h/ABIC9uC0XHCih1dXWuruP2OAD+YzmjDbwW0dDQkKqqqpRMJlVZWVns5gA4R7pQ9Py/NizLkiR1dXUpEomMG1CampoUCoXU398/at2HZVmybVu9vb1MuwV8JJ/nN+EDgCupVEqhUGjMeo10aNi8ebPuueeecQOKJEWjUUnKOu78EAPAP/J5flNwCsAVt4WiP/jBD3LOZGlqalJXV5fmzJmTdYxt2wQPYAKg5gOAK24LQI8fPz7mvnNnskQiETU1NbHCKTABET4AuOJlAWg6yAQCATU0NHh2XgD+ULBhly1btigUCunSSy/VkiVL9Jvf/KZQlwJgQDgclm3bmbqM81mWperqalfnYiYLMLEVJHw8//zzWrdunTZs2KC3335bixYt0vLly3Xs2LFCXA6AAYFAQO3t7ZI0IoCkv2/ZsiVnQAkGgwqHw4VtLICSVpDwsXnzZj300EN64IEHdN111+nZZ5/V5Zdfrn/5l38pxOUAGBKJRMYtFL377rtzBpS2tjbqOoAJzvOptl988YUuv/xydXV1acWKFZntq1ev1okTJ7Rjx46s44eHhzU8PJz5PjQ0pGAwyFRboITlWuF0tHU+gsGg2tramMkClKl8ptp6XnD6u9/9TqlUSjU1NVnba2pq9OGHH444ftOmTXr88ce9bgaAAspVKMpMFgDjKfpsl/Xr12vdunWZ7+meDwD+xkwWAGPxPHzMnDlTgUBAR48ezdp+9OhR1dbWjji+oqJCFRUVXjcDAACUKM8LTqdMmaLFixdr165dmW1nz57Vrl27VF9f7/XlAACAzxRk2GXdunVavXq1vvWtb+mmm25SW1ubTp06pQceeKAQlwMAAD5SkPBx77336vjx43rsscc0ODioP/mTP9HOnTtHFKECAICJh7faAgCAi8ZbbQEAQMkifAAAAKMIHwAAwCjCBwAAMKroK5yeL13/OjQ0VOSWAAAAt9LPbTfzWEoufJw8eVKSWGIdAAAfOnnypKqqqsY9puSm2p49e1affPKJpk2bNuKV3Bcr/d6Yvr4+pvEawP02i/ttFvfbLO63WRdyvx3H0cmTJzV79mxNmjR+VUfJ9XxMmjRJtm0X9BqVlZX88hrE/TaL+20W99ss7rdZ+d7vXD0eaRScAgAAowgfAADAqAkVPioqKrRhwwZVVFQUuykTAvfbLO63Wdxvs7jfZhX6fpdcwSkAAChvE6rnAwAAFB/hAwAAGEX4AAAARhE+AACAURMmfGzZskWhUEiXXnqplixZot/85jfFblLZ2LNnj+644w7Nnj1blmXpxRdfzNrvOI4ee+wx1dXV6bLLLtOyZcv00UcfFaexPrdp0ybdeOONmjZtmmbNmqUVK1bowIEDWcecPn1azc3NuvLKKzV16lTdddddOnr0aJFa7G/PPPOMFi5cmFloqb6+Xi+//HJmP/e6sJ544glZlqXW1tbMNu65dzZu3CjLsrI+CxYsyOwv5L2eEOHj+eef17p167Rhwwa9/fbbWrRokZYvX65jx44Vu2ll4dSpU1q0aJG2bNky6v4nn3xSTz/9tJ599lm9+eabuuKKK7R8+XKdPn3acEv9b/fu3WpubtYbb7yhV155RV9++aVuvfVWnTp1KnPMI488opdeekkvvPCCdu/erU8++USRSKSIrfYv27b1xBNPaN++fXrrrbf0F3/xF2pqatJ//dd/SeJeF9Jvf/tb/fznP9fChQuztnPPvXX99ddrYGAg8/n1r3+d2VfQe+1MADfddJPT3Nyc+Z5KpZzZs2c7mzZtKmKrypMkZ/v27ZnvZ8+edWpra52nnnoqs+3EiRNORUWF09nZWYQWlpdjx445kpzdu3c7jvPVvb3kkkucF154IXPMf//3fzuSnL179xarmWXla1/7mvPP//zP3OsCOnnypHPNNdc4r7zyivPnf/7nTktLi+M4/H57bcOGDc6iRYtG3Vfoe132PR9ffPGF9u3bp2XLlmW2TZo0ScuWLdPevXuL2LKJobe3V4ODg1n3v6qqSkuWLOH+eyCZTEqSZsyYIUnat2+fvvzyy6z7vWDBAs2dO5f7fZFSqZS2bdumU6dOqb6+nntdQM3NzfrOd76TdW8lfr8L4aOPPtLs2bN11VVX6b777tPhw4clFf5el9yL5bz2u9/9TqlUSjU1NVnba2pq9OGHHxapVRPH4OCgJI16/9P7cGHOnj2r1tZW3XzzzbrhhhskfXW/p0yZounTp2cdy/2+cO+9957q6+t1+vRpTZ06Vdu3b9d1112n/fv3c68LYNu2bXr77bf129/+dsQ+fr+9tWTJEm3dulXXXnutBgYG9PjjjyscDuv9998v+L0u+/ABlKvm5ma9//77WWO08N61116r/fv3K5lMqqurS6tXr9bu3buL3ayy1NfXp5aWFr3yyiu69NJLi92csnf77bdn/nvhwoVasmSJ5s2bp3//93/XZZddVtBrl/2wy8yZMxUIBEZU6B49elS1tbVFatXEkb7H3H9vrV27Vr/85S8Vj8dl23Zme21trb744gudOHEi63ju94WbMmWKvv71r2vx4sXatGmTFi1apPb2du51Aezbt0/Hjh3Tn/7pn2ry5MmaPHmydu/eraefflqTJ09WTU0N97yApk+frm984xs6ePBgwX+/yz58TJkyRYsXL9auXbsy286ePatdu3apvr6+iC2bGObPn6/a2tqs+z80NKQ333yT+38BHMfR2rVrtX37dr322muaP39+1v7FixfrkksuybrfBw4c0OHDh7nfHjl79qyGh4e51wWwdOlSvffee9q/f3/m861vfUv33Xdf5r+554Xz2Wef6eOPP1ZdXV3hf78vumTVB7Zt2+ZUVFQ4W7dudT744APn+9//vjN9+nRncHCw2E0rCydPnnTeeecd55133nEkOZs3b3beeecd53//938dx3GcJ554wpk+fbqzY8cO591333Wampqc+fPnO3/4wx+K3HL/WbNmjVNVVeUkEglnYGAg8/n8888zxzz88MPO3Llznddee8156623nPr6eqe+vr6IrfavH/3oR87u3bud3t5e591333V+9KMfOZZlOf/xH//hOA732oRzZ7s4DvfcS48++qiTSCSc3t5e5/XXX3eWLVvmzJw50zl27JjjOIW91xMifDiO4/zTP/2TM3fuXGfKlCnOTTfd5LzxxhvFblLZiMfjjqQRn9WrVzuO89V025/85CdOTU2NU1FR4SxdutQ5cOBAcRvtU6PdZ0nOc889lznmD3/4g/ODH/zA+drXvuZcfvnlzp133ukMDAwUr9E+9r3vfc+ZN2+eM2XKFKe6utpZunRpJng4DvfahPPDB/fcO/fee69TV1fnTJkyxZkzZ45z7733OgcPHszsL+S9thzHcS6+/wQAAMCdsq/5AAAApYXwAQAAjCJ8AAAAowgfAADAKMIHAAAwivABAACMInwAAACjCB8AAMAowgcAADCK8AEAAIwifAAAAKMIHwAAwKj/BwIOwglHG2H1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we initialize a `gradient_booster` instance, fit it to our data, and obtain predictions on the same training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = gradient_booster(n_estimators = 60, eta = 0.1, min_samples_split=2, max_depth=3)\n",
    "\n",
    "gbm.fit(x, y)\n",
    "preds = gbm.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the prediction, we will have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(x, y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident, we've overfitted to the data, highlighting the learning capacity of our developed model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Have Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this discussion, we accomplished the following:\n",
    "\n",
    "* Revisited our classification decision tree implementation and adapted it to a regression decision tree.\n",
    "* Briefly reviewed the concept of boosting.\n",
    "* Implemented boosted regression trees.\n",
    "* Created a simple regression dataset.\n",
    "* Generated predictions using the trained boosted trees and visualized them through plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you have enjoyed this lesson!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
