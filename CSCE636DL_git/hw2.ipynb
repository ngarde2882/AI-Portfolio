{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) \n",
    "#### use gradient tape to find the derivtive of the function f(x) = sin(x) for x = [0,0.1,0.2,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.        0.9950042 0.9800666 0.9553365], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Nicholas Garde\n",
    "# 227006946\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "input_var = tf.Variable([0,0.1,0.2,0.3])\n",
    "with tf.GradientTape() as tape:\n",
    "   result = tf.sin(input_var)\n",
    "gradient = tape.gradient(result, input_var)\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)\n",
    "#### \"Classifying movie reviews: A binary classification example\" tune, display results on train,vali,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = \" \".join(\n",
    "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence:\n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_train = np.asarray(train_labels).astype(\"float32\")\n",
    "y_test = np.asarray(test_labels).astype(\"float32\")\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 0.01 lr, 3 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8830000162124634 New best model found!\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8891000151634216 New best model found!\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8823999762535095 New #3 model found!\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8845000267028809 New #2 model found!\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8885999917984009 New #2 model found!\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8748000264167786\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8859000205993652 New #3 model found!\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8894000053405762 New best model found!\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8865000009536743\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8831999897956848\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8845000267028809\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8848999738693237\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.883899986743927\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8894000053405762 New best model found!\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8802000284194946\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8884999752044678\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8263999819755554\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8830000162124634\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8894000053405762 New best model found!\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8828999996185303\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8826000094413757\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8733000159263611\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8830999732017517\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8880000114440918\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884999752044678\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8827000260353088\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.885699987411499\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8773000240325928\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8891000151634216\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8777999877929688\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.88919997215271\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884999752044678\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8931000232696533 New best model found!\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8335999846458435\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8845000267028809\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8892999887466431\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.5187000036239624\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8895999789237976 New #2 model found!\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8925999999046326 New #2 model found!\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8483999967575073\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.887499988079071\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8896999955177307 New #3 model found!\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8330000042915344\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8913999795913696 New #3 model found!\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8913000226020813\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.7860000133514404\n",
      "Training model with 0.01 lr, 3 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8863000273704529\n",
      "Training model with 0.001 lr, 3 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8899000287055969\n",
      "Training model with 0.0001 lr, 3 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8518000245094299\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8816999793052673\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888000249862671\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8907999992370605\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8770999908447266\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8884999752044678\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8865000009536743\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8853999972343445\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8895000219345093\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8838000297546387\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.890500009059906\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8901000022888184\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8895999789237976\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8903999924659729\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8901000022888184\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8808000087738037\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8896999955177307\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8910999894142151\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8845000267028809\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8870999813079834\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8898000121116638\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8727999925613403\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8885999917984009\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8808000087738037\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8812000155448914\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8894000053405762\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.870199978351593\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8877999782562256\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8844000101089478\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8899999856948853\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8907999992370605\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.871999979019165\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8870999813079834\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8871999979019165\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8917999863624573 New #3 model found!\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8902000188827515\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.824999988079071\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8841999769210815\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8339999914169312\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8899999856948853\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8916000127792358\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8438000082969666\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8889999985694885\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8891000151634216\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.847100019454956\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8934000134468079 New best model found!\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8899999856948853\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8792999982833862\n",
      "Training model with 0.01 lr, 3 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.001 lr, 3 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8895999789237976\n",
      "Training model with 0.0001 lr, 3 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8709999918937683\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8804000020027161\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8895999789237976\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8787000179290771\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8896999955177307\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8894000053405762\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8835999965667725\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8909000158309937\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8895000219345093\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8715000152587891\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8898000121116638\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8892999887466431\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8837000131607056\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8860999941825867\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8790000081062317\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8881000280380249\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8885999917984009\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8819000124931335\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8914999961853027\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8700000047683716\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8877999782562256\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8823000192642212\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8708999752998352\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8884999752044678\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8798999786376953\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8859999775886536\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8690999746322632\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8873000144958496\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8870000243186951\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8892999887466431\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8554999828338623\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8817999958992004\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8885999917984009\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8449000120162964\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8848999738693237\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8924000263214111\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8734999895095825\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8817999958992004\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8885999917984009\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.862500011920929\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8871999979019165\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8901000022888184\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8871999979019165\n",
      "Training model with 0.01 lr, 3 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8823999762535095\n",
      "Training model with 0.001 lr, 3 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.0001 lr, 3 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8823999762535095\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8860999941825867\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8876000046730042\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8909000158309937\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8716999888420105\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8877999782562256\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8895999789237976\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8859999775886536\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8863999843597412\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8892999887466431\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8740000128746033\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8876000046730042\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8894000053405762\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8758999705314636\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.887499988079071\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8690999746322632\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8865000009536743\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.879800021648407\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8855999708175659\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8883000016212463\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8637999892234802\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8885999917984009\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.88919997215271\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8815000057220459\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8858000040054321\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8895999789237976\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8665000200271606\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8866000175476074\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8833000063896179\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8837000131607056\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8894000053405762\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8723999857902527\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8859000205993652\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8896999955177307\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8798999786376953\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8892999887466431\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8747000098228455\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8826000094413757\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8888000249862671\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.859000027179718\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8891000151634216\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8822000026702881\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8788999915122986\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8899999856948853\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8790000081062317\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884999752044678\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.890500009059906\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8920999765396118\n",
      "Training model with 0.01 lr, 3 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8833000063896179\n",
      "Training model with 0.001 lr, 3 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8876000046730042\n",
      "Training model with 0.0001 lr, 3 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8888000249862671\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8849999904632568\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8902000188827515\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8321999907493591\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8780999779701233\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8823000192642212\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8860999941825867\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.886900007724762\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8758000135421753\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8899999856948853\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8833000063896179\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8827999830245972\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8920000195503235\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8777999877929688\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8899000287055969\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8859999775886536\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8828999996185303\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8902999758720398\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8691999912261963\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8871999979019165\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8816999793052673\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8777999877929688\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8866000175476074\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.887499988079071\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8672999739646912\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8901000022888184\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8828999996185303\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8847000002861023\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8853999972343445\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8736000061035156\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8880000114440918\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8873999714851379\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8902000188827515\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.505299985408783\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8895000219345093\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.505299985408783\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8849999904632568\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8912000060081482\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8396000266075134\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8899000287055969\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8917999863624573\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.505299985408783\n",
      "Training model with 0.01 lr, 5 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8830999732017517\n",
      "Training model with 0.001 lr, 5 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8883000016212463\n",
      "Training model with 0.0001 lr, 5 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8454999923706055\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8845999836921692\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8862000107765198\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8907999992370605\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8737000226974487\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8902999758720398\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8809000253677368\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8873999714851379\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8914999961853027\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8705000281333923\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8899999856948853\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8910999894142151\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.886900007724762\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.88919997215271\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8686000108718872\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8845999836921692\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8808000087738037\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8876000046730042\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.887499988079071\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.858299970626831\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8842999935150146\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8841999769210815\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.885200023651123\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8880000114440918\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8891000151634216\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8574000000953674\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8835999965667725\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8873999714851379\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8826000094413757\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8845000267028809\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8898000121116638\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8691999912261963\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8855000138282776\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.885699987411499\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8845000267028809\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8920999765396118\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.6452999711036682\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8797000050544739\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8873000144958496\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8816999793052673\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.891700029373169\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8831999897956848\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.890500009059906\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.7666000127792358\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8784000277519226\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8906000256538391\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8708000183105469\n",
      "Training model with 0.01 lr, 5 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8798999786376953\n",
      "Training model with 0.001 lr, 5 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.0001 lr, 5 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8784000277519226\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8812000155448914\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8899999856948853\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8677999973297119\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8866999745368958\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8892999887466431\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8891000151634216\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8895000219345093\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8910999894142151\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8652999997138977\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8865000009536743\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.890500009059906\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8822000026702881\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8860999941825867\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8910999894142151\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8705000281333923\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8809000253677368\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8848999738693237\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8860999941825867\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8622999787330627\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8827999830245972\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8867999911308289\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8853999972343445\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8852999806404114\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.886900007724762\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8528000116348267\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8822000026702881\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8858000040054321\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8820000290870667\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.886900007724762\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8605999946594238\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.88919997215271\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.887499988079071\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8838000297546387\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8919000029563904\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8468999862670898\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8745999932289124\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8876000046730042\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.7236999869346619\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8791000247001648\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8903999924659729\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8776000142097473\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8762000203132629\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8712000250816345\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8766999840736389\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8925999999046326 New #3 model found!\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8930000066757202 New #3 model found!\n",
      "Training model with 0.01 lr, 5 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8738999962806702\n",
      "Training model with 0.001 lr, 5 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8883000016212463\n",
      "Training model with 0.0001 lr, 5 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8866999745368958\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8880000114440918\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8569999933242798\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8837000131607056\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8866999745368958\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8784999847412109\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8899000287055969\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8892999887466431\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8574000000953674\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8845000267028809\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8884999752044678\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.878600001335144\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8873000144958496\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8507000207901001\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8870000243186951\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.880299985408783\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8822000026702881\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.883899986743927\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8536999821662903\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8763999938964844\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8863000273704529\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8783000111579895\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8880000114440918\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8855000138282776\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8327999711036682\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8779000043869019\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8848000168800354\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8820000290870667\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8862000107765198\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8830999732017517\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8547000288963318\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8819000124931335\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.886900007724762\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8773000240325928\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888000249862671\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8557000160217285\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8784999847412109\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8881000280380249\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.870199978351593\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8792999982833862\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888000249862671\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8873999714851379\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8639000058174133\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8853999972343445\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8858000040054321\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8762000203132629\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8877999782562256\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.890500009059906\n",
      "Training model with 0.01 lr, 5 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8587999939918518\n",
      "Training model with 0.001 lr, 5 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8862000107765198\n",
      "Training model with 0.0001 lr, 5 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8883000016212463\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8784999847412109\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8823999762535095\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8755000233650208\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8679999709129333\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8906000256538391\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8863999843597412\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8762999773025513\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8894000053405762\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8826000094413757\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8815000057220459\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8792999982833862\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8880000114440918\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.876800000667572\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8877999782562256\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8899000287055969\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8779000043869019\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8870999813079834\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8867999911308289\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8478999733924866\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8824999928474426\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8828999996185303\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8824999928474426\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8866999745368958\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8838000297546387\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8580999970436096\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8852999806404114\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.885699987411499\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8820000290870667\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8827999830245972\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8822000026702881\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8439000248908997\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.885200023651123\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8842999935150146\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8772000074386597\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8799999952316284\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8899000287055969\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8799999952316284\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8795999884605408\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8726000189781189\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8544999957084656\n",
      "Training model with 0.01 lr, 7 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8758999705314636\n",
      "Training model with 0.001 lr, 7 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8877000212669373\n",
      "Training model with 0.0001 lr, 7 layers, 8 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.505299985408783\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8842999935150146\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8862000107765198\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8898000121116638\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.859499990940094\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8804000020027161\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8859999775886536\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8672000169754028\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.885699987411499\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8741999864578247\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8885999917984009\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8870999813079834\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8669999837875366\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8901000022888184\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8761000037193298\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8799999952316284\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8842999935150146\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8457000255584717\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8852999806404114\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8815000057220459\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8748999834060669\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.879800021648407\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8859000205993652\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.826200008392334\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8802000284194946\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8859000205993652\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8812999725341797\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8842999935150146\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8873000144958496\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8384000062942505\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8805000185966492\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8873999714851379\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8855000138282776\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8876000046730042\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8754000067710876\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8873999714851379\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8783000111579895\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.888700008392334\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.5012999773025513\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8666999936103821\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.885699987411499\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.505299985408783\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8743000030517578\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8873999714851379\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8766000270843506\n",
      "Training model with 0.01 lr, 7 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8605999946594238\n",
      "Training model with 0.001 lr, 7 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8870000243186951\n",
      "Training model with 0.0001 lr, 7 layers, 16 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8686000108718872\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8805000185966492\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8844000101089478\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.885699987411499\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8374000191688538\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8891000151634216\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8799999952316284\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8781999945640564\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8669999837875366\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8838000297546387\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8881999850273132\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8855000138282776\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8805000185966492\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8880000114440918\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8549000024795532\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8834999799728394\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8859999775886536\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.882099986076355\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8823000192642212\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8851000070571899\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8529999852180481\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8790000081062317\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8870000243186951\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8763999938964844\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8806999921798706\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8853999972343445\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8267999887466431\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8744999766349792\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8855000138282776\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8809999823570251\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8867999911308289\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8797000050544739\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8381999731063843\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8812999725341797\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8852999806404114\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8762000203132629\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888000249862671\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.5525000095367432\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8547000288963318\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8847000002861023\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8744999766349792\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8884000182151794\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.5016999840736389\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8619999885559082\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8862000107765198\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8759999871253967\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.886900007724762\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8896999955177307\n",
      "Training model with 0.01 lr, 7 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8503999710083008\n",
      "Training model with 0.001 lr, 7 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.886900007724762\n",
      "Training model with 0.0001 lr, 7 layers, 32 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8866999745368958\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.883899986743927\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8866000175476074\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, relu activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8866000175476074\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.847599983215332\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, relu activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8865000009536743\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8830999732017517\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8781999945640564\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, relu activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8852999806404114\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8460000157356262\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8812999725341797\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, relu activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8870999813079834\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8831999897956848\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8794999718666077\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, relu activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8878999948501587\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8180000185966492\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8801000118255615\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, relu activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8877999782562256\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8797000050544739\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8842999935150146\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, tanh activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8845999836921692\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.5375999808311462\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8762999773025513\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, tanh activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8834999799728394\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8784999847412109\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, tanh activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8790000081062317\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8197000026702881\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.870199978351593\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, tanh activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8859000205993652\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8815000057220459\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8855000138282776\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, tanh activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8834999799728394\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8216000199317932\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8686000108718872\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, tanh activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8840000033378601\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8754000067710876\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8859999775886536\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, sigmoid activation, 20 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8417999744415283\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8564000129699707\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.8827999830245972\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, sigmoid activation, 20 epochs, hinge loss\n",
      "Model accuracy: 0.505299985408783\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8744999766349792\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888000249862671\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, sigmoid activation, 30 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8765000104904175\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.49470001459121704\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.879800021648407\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, sigmoid activation, 30 epochs, hinge loss\n",
      "Model accuracy: 0.8787999749183655\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8774999976158142\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8855000138282776\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n",
      "Model accuracy: 0.8888999819755554\n",
      "Training model with 0.01 lr, 7 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8456000089645386\n",
      "Training model with 0.001 lr, 7 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8813999891281128\n",
      "Training model with 0.0001 lr, 7 layers, 64 neurons, sigmoid activation, 50 epochs, hinge loss\n",
      "Model accuracy: 0.8855999708175659\n",
      "0.8934 0.01lr 3l 16n sigmoid 50ep binary_crossentropy\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.8551 - loss: 0.8666\n",
      "Model 1: Test Accuracy = 0.8556, Validation Accuracy = 0.8934\n",
      "0.8931 0.001lr 3l 8n sigmoid 20ep binary_crossentropy\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.8808 - loss: 0.3390\n",
      "Model 2: Test Accuracy = 0.8828, Validation Accuracy = 0.8931\n",
      "0.8930 0.0001lr 5l 32n sigmoid 50ep binary_crossentropy\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 0.8819 - loss: 0.2946\n",
      "Model 3: Test Accuracy = 0.8840, Validation Accuracy = 0.8930\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import copy\n",
    "\n",
    "D = {\n",
    "    'layers': [3,5,7],\n",
    "    'neurons': [8,16,32,64],\n",
    "    'activation': ['relu','tanh','sigmoid'],\n",
    "    'epochs': [20,30,50],\n",
    "    'loss': ['binary_crossentropy','hinge'],\n",
    "    'learning_rate': [0.01,0.001,0.0001]\n",
    "}\n",
    "\n",
    "# Track top 3 models\n",
    "best_models = []\n",
    "\n",
    "def update_best_models(model, history, learning_rate, lyers, neurons, activation, epochs, loss):\n",
    "    global best_models\n",
    "    val_acc = max(history['val_accuracy'])  # Get best validation accuracy\n",
    "    print(f\"Model accuracy: {val_acc}\",end='')\n",
    "    \n",
    "    # Store model details\n",
    "    model_entry = {\n",
    "        'val_acc': val_acc,\n",
    "        'model_config': model.to_json(),\n",
    "        'model_weights': copy.deepcopy(model.get_weights()),\n",
    "        'layers': lyers,\n",
    "        'neurons': neurons,\n",
    "        'activation': activation,\n",
    "        'epochs': epochs,\n",
    "        'loss': loss,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    \n",
    "    # Maintain top 3 models\n",
    "    best_models.append(model_entry)\n",
    "    best_models = sorted(best_models, key=lambda x: x['val_acc'], reverse=True)[:3]\n",
    "    if best_models[0]['val_acc'] == val_acc: print(\" New best model found!\")\n",
    "    elif best_models[1]['val_acc'] == val_acc: print(\" New #2 model found!\")\n",
    "    elif best_models[2]['val_acc'] == val_acc: print(\" New #3 model found!\")\n",
    "    else: print('')\n",
    "\n",
    "for lyers in D['layers']:\n",
    "    for neurons in D['neurons']:\n",
    "        for activation in D['activation']:\n",
    "            for epochs in D['epochs']:\n",
    "                for loss in D['loss']:\n",
    "                    for learning_rate in D['learning_rate']:\n",
    "                        print(f\"Training model with {learning_rate} lr, {lyers} layers, {neurons} neurons, {activation} activation, {epochs} epochs, {loss} loss\")\n",
    "                        model_layers = [layers.Dense(neurons, activation=activation)]\n",
    "                        for _ in range(lyers - 2):\n",
    "                            model_layers.append(layers.Dense(neurons, activation=activation))\n",
    "                        model_layers.append(layers.Dense(1, activation=\"sigmoid\"))\n",
    "                        model = keras.Sequential(model_layers)\n",
    "                        \n",
    "                        model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                    loss=loss,\n",
    "                                    metrics=['accuracy'])\n",
    "                        \n",
    "                        history = model.fit(partial_x_train,\n",
    "                                            partial_y_train,\n",
    "                                            epochs=epochs,\n",
    "                                            batch_size=512,\n",
    "                                            validation_data=(x_val, y_val),\n",
    "                                            verbose=0).history\n",
    "                        \n",
    "                        update_best_models(model, history, learning_rate, lyers, neurons, activation, epochs, loss)\n",
    "                    \n",
    "# Compare the top 3 models on the test set\n",
    "for i, model_entry in enumerate(best_models):\n",
    "    print(f'{model_entry[\"val_acc\"]:.4f} {model_entry[\"learning_rate\"]}lr {model_entry[\"layers\"]}l {model_entry[\"neurons\"]}n {model_entry[\"activation\"]} {model_entry[\"epochs\"]}ep {model_entry[\"loss\"]}')\n",
    "    restored_model = keras.models.model_from_json(model_entry['model_config'])\n",
    "    restored_model.set_weights(model_entry['model_weights'])\n",
    "    restored_model.compile(optimizer=keras.optimizers.Adam(learning_rate=model_entry['learning_rate']), loss=model_entry['loss'], metrics=['accuracy'])\n",
    "    test_loss, test_acc = restored_model.evaluate(x_test, y_test)\n",
    "    print(f\"Model {i+1}: Test Accuracy = {test_acc:.4f}, Validation Accuracy = {model_entry['val_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 0.0001 lr, 5 layers, 32 neurons, sigmoid activation, 50 epochs, binary_crossentropy loss\n"
     ]
    }
   ],
   "source": [
    "learning_rate = best_models[2]['learning_rate']\n",
    "lyers = best_models[2]['layers']\n",
    "neurons = best_models[2]['neurons']\n",
    "activation = best_models[2]['activation']\n",
    "epochs = best_models[2]['epochs']\n",
    "loss = best_models[2]['loss']\n",
    "\n",
    "print(f\"Training model with {learning_rate} lr, {lyers} layers, {neurons} neurons, {activation} activation, {epochs} epochs, {loss} loss\")\n",
    "model_layers = [layers.Dense(neurons, activation=activation)]\n",
    "for _ in range(lyers - 2):\n",
    "    model_layers.append(layers.Dense(neurons, activation=activation))\n",
    "model_layers.append(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model = keras.Sequential(model_layers)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss=loss,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1).history\n",
    "print(f\"Model accuracy: {max(history['val_accuracy'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_values = history[\"loss\"]\n",
    "val_loss_values = history[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "acc = history[\"accuracy\"]\n",
    "val_acc = history[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.plot(epochs, loss_values, \"ro\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"r\", label=\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8934 0.01lr 3l 16n sigmoid 50ep binary_crossentropy\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.8551 - loss: 0.8666\n",
      "Test Accuracy = 0.8556, Validation Accuracy = 0.8934\n",
      "0.8931 0.001lr 3l 8n sigmoid 20ep binary_crossentropy\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.8808 - loss: 0.3390\n",
      "Test Accuracy = 0.8828, Validation Accuracy = 0.8931\n",
      "0.8930 0.0001lr 5l 32n sigmoid 50ep binary_crossentropy\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.8819 - loss: 0.2946\n",
      "Test Accuracy = 0.8840, Validation Accuracy = 0.8930\n"
     ]
    }
   ],
   "source": [
    "for model in best_models:\n",
    "    print(f'{model[\"val_acc\"]:.4f} {model[\"learning_rate\"]}lr {model[\"layers\"]}l {model[\"neurons\"]}n {model[\"activation\"]} {model[\"epochs\"]}ep {model[\"loss\"]}')\n",
    "    restored_model = keras.models.model_from_json(model['model_config'])\n",
    "    restored_model.set_weights(model['model_weights'])\n",
    "    restored_model.compile(optimizer=keras.optimizers.Adam(learning_rate=model['learning_rate']), loss=model['loss'], metrics=['accuracy'])\n",
    "    test_loss, test_acc = restored_model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Accuracy = {test_acc:.4f}, Validation Accuracy = {model['val_acc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
