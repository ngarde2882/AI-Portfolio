{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DF (10980480, 5)\n",
      "Index(['n', 'k', 'm', 'result', 'P'], dtype='object')\n",
      "    n  k  m       result                                                  P\n",
      "0  10  5  2   266.264524  [-53.30165452517249, 46.36747377721454, 12.267...\n",
      "1   9  4  2   140.163560  [6.5178894459618135, -6.281201889271188, 99.66...\n",
      "2  10  4  3   167.692765  [-67.02930762978451, 82.95217006264068, -6.583...\n",
      "3   9  4  3   565.010999  [91.14110355866848, -15.260304068831033, -47.3...\n",
      "4   9  6  2  1170.076493  [92.83943954357875, -97.82331459868368, 5.3277...\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# fetch training data (thank you keegan)\n",
    "df = load('../DL_data/results_dataframe/results_dataframe.pkl')\n",
    "print(type(df))\n",
    "print(f'DF {df.shape}')\n",
    "print(df.columns)\n",
    "\n",
    "def normalize_P(df):\n",
    "    def norm(x):\n",
    "        x = np.array(x, dtype=np.float32)\n",
    "        return ((x - -100) / (100 - -100)) * 2 - 1\n",
    "    return df['P'].apply(lambda x: norm(x).tolist())\n",
    "# df['P'] = normalize_P(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "num_train_samples: 13000 num_val_samples: 5000 num_test_samples: 2000\n",
      "modle created\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 287\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodle created\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    286\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 287\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m test_and_plot(model, test_loader)\n",
      "Cell \u001b[1;32mIn[5], line 148\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, optimizer, config, epochs)\u001b[0m\n\u001b[0;32m    145\u001b[0m P_tensor, m_tensor, target \u001b[38;5;241m=\u001b[39m P_tensor\u001b[38;5;241m.\u001b[39mto(device), m_tensor\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    147\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 148\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, target)\n\u001b[0;32m    150\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 120\u001b[0m, in \u001b[0;36mCNNTransformerModel.forward\u001b[1;34m(self, P, m)\u001b[0m\n\u001b[0;32m    117\u001b[0m token_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([m_token, tokens], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, 61, d_model)\u001b[39;00m\n\u001b[0;32m    119\u001b[0m encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(token_seq)    \u001b[38;5;66;03m# Add positional info\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, 61, d_model)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m pooled \u001b[38;5;241m=\u001b[39m transformed[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Use m-token output (position 0)\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregressor(pooled)\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:415\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    412\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 415\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    418\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:749\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    747\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 749\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    750\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:757\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[0;32m    756\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 757\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\nick2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:5504\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5501\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m   5502\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m-> 5504\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5505\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[0;32m   5507\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def pad_matrix(P, target_shape=(6, 10)):\n",
    "    \"\"\"\n",
    "    Pad a matrix P (shape [k, n-k]) to shape [6, 10]\n",
    "    \"\"\"\n",
    "    P = np.array(P, dtype=np.float32)\n",
    "    padded = np.zeros(target_shape, dtype=np.float32)\n",
    "    k, n_k = P.shape\n",
    "    padded[:k, :n_k] = P\n",
    "    return padded\n",
    "\n",
    "class CNNTransformerDataset(Dataset):\n",
    "    def __init__(self, df, normalize=True, include_m=True):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            df (pd.DataFrame): must contain 'P', 'm', 'n', 'k', and optionally 'result'\n",
    "            normalize (bool): scale P values from [-100, 100] to [-1, 1]\n",
    "            include_m (bool): include scalar m as auxiliary input\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.normalize = normalize\n",
    "        self.include_m = include_m\n",
    "        self.has_targets = 'result' in df.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def normalize_P(self, P, k, n_k):\n",
    "        P = np.array(P, dtype=np.float32).reshape(k, n_k)\n",
    "        return ((P + 100) / 200) * 2 - 1 if self.normalize else P\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        k, n = int(row['k']), int(row['n'])\n",
    "        n_k = n - k\n",
    "\n",
    "        P = self.normalize_P(row['P'], k, n_k)\n",
    "        P = pad_matrix(P)  # pad to [6, 10]\n",
    "        P_tensor = torch.tensor(P).unsqueeze(0)  # [1, 6, 10]\n",
    "\n",
    "        if self.include_m:\n",
    "            m_tensor = torch.tensor([row['m']], dtype=torch.float32)\n",
    "        else:\n",
    "            m_tensor = None\n",
    "\n",
    "        if self.has_targets:\n",
    "            y = torch.tensor(row['result'], dtype=torch.float32)\n",
    "            return P_tensor, m_tensor, y\n",
    "        else:\n",
    "            return P_tensor, m_tensor\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)].to(x.device)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNTransformerModel(nn.Module):\n",
    "    def __init__(self, token_dim=128, d_model=128, nhead=8, num_layers=4, dim_feedforward=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token_dim = token_dim\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # CNN to extract token sequence from padded 6x10 P matrix\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, token_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(token_dim, token_dim // 2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(token_dim // 2, token_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.m_project = nn.Linear(1, d_model)  # Project scalar m into token space\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.input_proj = nn.Linear(token_dim, d_model)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, P, m):\n",
    "        # P: (B, 1, 6, 10), m: (B, 1)\n",
    "        B = P.size(0)\n",
    "\n",
    "        cnn_out = self.cnn(P)               # (B, token_dim, 6, 10)\n",
    "        tokens = cnn_out.flatten(2).transpose(1, 2)  # (B, 60, token_dim)\n",
    "        tokens = self.input_proj(tokens)   # (B, 60, d_model)\n",
    "\n",
    "        m_token = self.m_project(m).unsqueeze(1)  # (B, 1, d_model)\n",
    "        token_seq = torch.cat([m_token, tokens], dim=1)  # (B, 61, d_model)\n",
    "\n",
    "        encoded = self.pos_encoder(token_seq)    # Add positional info\n",
    "        transformed = self.transformer(encoded)  # (B, 61, d_model)\n",
    "\n",
    "        pooled = transformed[:, 0]  # Use m-token output (position 0)\n",
    "        return self.regressor(pooled)  # Final regression prediction\n",
    "\n",
    "\n",
    "def ratio_loss(preds, targets, eps=1e-6):\n",
    "    preds = torch.clamp(preds, min=eps)\n",
    "    targets = torch.clamp(targets, min=eps)\n",
    "    return torch.mean((torch.log2(targets) - torch.log2(preds))**2)\n",
    "criterion = ratio_loss\n",
    "\n",
    "def train(model, train_loader, val_loader, optimizer, config, epochs=25):\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    no_improve_epochs = 0\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for P_tensor, m_tensor, target in train_loader:\n",
    "            P_tensor, m_tensor, target = P_tensor.to(device), m_tensor.to(device), target.to(device).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(P_tensor, m_tensor)\n",
    "            loss = criterion(preds, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * P_tensor.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for P_tensor, m_tensor, target in val_loader:\n",
    "                P_tensor, m_tensor, target = P_tensor.to(device), m_tensor.to(device), target.to(device).unsqueeze(1)\n",
    "                preds = model(P_tensor, m_tensor)\n",
    "                loss = criterion(preds, target)\n",
    "                running_val_loss += loss.item() * P_tensor.size(0)\n",
    "\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: train loss {train_loss:.4f}, val loss {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save({\n",
    "                'model_state_dict': best_model_state,\n",
    "                'config': config\n",
    "            }, f\"model3{config['flag']}.pt\")\n",
    "            print(f\"Best model saved at epoch {epoch+1} with val loss: {best_val_loss:.4f}\")\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "\n",
    "        if LENIENT:\n",
    "            if no_improve_epochs > 4: print('terminating training'); break\n",
    "            if epoch > 2 and val_loss > 500: print('terminating training'); break\n",
    "        else:\n",
    "            if no_improve_epochs > 2: print('terminating training'); break\n",
    "\n",
    "    # Plot losses\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train loss\")\n",
    "    plt.plot(val_losses, label=\"Val loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.title(f\"Training and Validation Losses\")\n",
    "    plt.show()\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_and_plot(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    total_loss = 0\n",
    "    criterion = ratio_loss\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for P_tensor, m_tensor, target in test_loader:\n",
    "            P_tensor, m_tensor, target = P_tensor.to(device), m_tensor.to(device), target.to(device).unsqueeze(1)\n",
    "            preds = model(P_tensor, m_tensor).reshape(-1)\n",
    "            loss = criterion(preds, target.reshape(-1))\n",
    "            total_loss += loss.item() * P_tensor.size(0)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(target.cpu().reshape(-1))\n",
    "\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    loss = total_loss / len(test_loader.dataset)\n",
    "    print(f\"Test Ratio Loss: {loss:.6f}\")\n",
    "\n",
    "    # Plotting\n",
    "    combined = np.concatenate([all_targets, all_preds])\n",
    "    low, high = np.percentile(combined, [0, 99])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(all_targets, all_preds, alpha=0.7)\n",
    "    plt.plot([low, high], [low, high], linestyle='--', label='Ideal')\n",
    "    plt.xlim(low, high); plt.ylim(low, high)\n",
    "    plt.xlabel(\"True target\"); plt.ylabel(\"Predicted\")\n",
    "    plt.title(f\"Test: True vs Predicted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(1706)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40\n",
    "# for n, k, m in [(9,4,5), (9,5,4), (9,6,3), (10,4,2), (10,4,6), (10,5,2), (10,5,5), (10,6,4)]:\n",
    "# for n in [9,10]:\n",
    "#     for k in [4,5,6]:\n",
    "#         for m in list(range(n-k+1))[2:]:\n",
    "\n",
    "LENIENT = True\n",
    "if device.type == \"cuda\":\n",
    "    data = df\n",
    "else: # <3 laptop\n",
    "    data = df.head(20000)\n",
    "num_train_samples = int(0.65 * len(data))\n",
    "num_val_samples = int(0.25 * len(data))\n",
    "num_test_samples = len(data) - num_train_samples - num_val_samples\n",
    "print(\"num_train_samples:\", num_train_samples,\"num_val_samples:\", num_val_samples,\"num_test_samples:\", num_test_samples)\n",
    "dataset = CNNTransformerDataset(data)\n",
    "train_data, val_data, test_data = random_split(dataset, [num_train_samples, num_val_samples, num_test_samples])\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "config = {\n",
    "    'token_dim': 256,\n",
    "    'd_model': 256,\n",
    "    'nhead': 16,\n",
    "    'num_layers': 4,\n",
    "    'dim_feedforward': 512,\n",
    "    'dropout': 0.1,\n",
    "    'lr': 0.00001,\n",
    "    'flag': 'a'\n",
    "}\n",
    "model_args = {key: config[key] for key in [\n",
    "    'token_dim', 'd_model', 'nhead', 'num_layers',\n",
    "    'dim_feedforward', 'dropout'\n",
    "]}\n",
    "model = CNNTransformerModel(**model_args).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "model = train(model, train_loader, val_loader, optimizer, config, epochs=EPOCHS)\n",
    "test_and_plot(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A\n",
    "'d_model': 512,\\\n",
    "'nhead': 8,\\\n",
    "'num_layers': 4,\\\n",
    "'dim_feedforward': 256,\\\n",
    "'dropout': 0.2,\\\n",
    "'lr': 0.000001,\\\n",
    "'flag': 'a'\\\n",
    "(9,4) Test Loss by m[2:]\\\n",
    ".2, .25, .9, 12.5\\\n",
    "(9,5) Test Loss by m[2:]\\\n",
    ".23, .87, 14.7\\\n",
    "(9,6) Test Loss by m[2:]\\\n",
    ".66, 8.9\\\n",
    "(10,4) Test Loss by m[2:]\\\n",
    ".85, .11, .29, 1.48, 24.6\\\n",
    "(10,5) Test Loss by m[2:]\\\n",
    ".13, .33, .97, 24.5\\\n",
    "(10,6) Test Loss by m[2:]\\\n",
    ".25, .89, 1297\n",
    "\n",
    "# B\n",
    "'d_model': 1024,\\\n",
    "'nhead': 16,\\\n",
    "'num_layers': 6,\\\n",
    "'dim_feedforward': 512,\\\n",
    "'dropout': 0.2,\\\n",
    "'lr': 0.0001,\\\n",
    "'flag': 'b'\\\n",
    "(9,4) Test Loss by m[2:]\\\n",
    "735.6, .26, 891, 3.4\\\n",
    "(9,5) Test Loss by m[2:]\\\n",
    ".25, 903, 3.48\\\n",
    "(9,6) Test Loss by m[2:]\\\n",
    ".66, 3.4\\\n",
    "(10,4) Test Loss by m[2:]\\\n",
    ".87, .12, .3, .95, 3.4\\\n",
    "(10,5) Test Loss by m[2:]\\\n",
    "770, .35, .95, 3.4\\\n",
    "(10,6) Test Loss by m[2:]\\\n",
    ".27, .9, 1297\n",
    "\n",
    "# C\n",
    "'d_model': 1024,\\\n",
    "'nhead': 32,\\\n",
    "'num_layers': 8,\\\n",
    "'dim_feedforward': 2048,\\\n",
    "'dropout': 0.2,\\\n",
    "'lr': 0.00005,\\\n",
    "'flag': 'c'\\\n",
    "(9,4) Test Loss by m[2:]\\\n",
    ".21, 785, .91, 3.4\\\n",
    "(9,5) Test Loss by m[2:]\\\n",
    ".23, .88, 3.4\\\n",
    "(9,6) Test Loss by m[2:]\\\n",
    ".67, 3.4\\\n",
    "(10,4) Test Loss by m[2:]\\\n",
    ".87, .12, .3, 921, 3.4\\\n",
    "(10,5) Test Loss by m[2:]\\\n",
    ".14, .35, .95, 3.5\\\n",
    "(10,6) Test Loss by m[2:]\\\n",
    ".26, .89, 3.5\n",
    "\n",
    "# D\n",
    "'d_model': 1024,\\\n",
    "'nhead': 16,\\\n",
    "'num_layers': 4,\\\n",
    "'dim_feedforward': 2048,\\\n",
    "'dropout': 0.2,\\\n",
    "'lr': 0.00001,\\\n",
    "'flag': 'd'\\\n",
    "(9,4) Test Loss by m[2:]\\\n",
    ".2, 785, .91, 3.4\\\n",
    "(9,5) Test Loss by m[2:]\\\n",
    ".24, .88, \\\n",
    "Terminated training.\n",
    "\n",
    "The larger models cut down on error at the higher m-values. Every model became a 1-value predictor for the optimal output to minimize overall loss. Rather than learning a pattern, these models (often) found the best single value to guess to minimize validation loss.\n",
    "\n",
    "Final ensemble:\\\n",
    "(9,4)[2,3,4] a\\\n",
    "(9,4)[5] c\\\n",
    "(9,5) c\\\n",
    "(9,6) b\\\n",
    "(10,4) b\\\n",
    "(10,5) c\\\n",
    "(10,7) c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_ensemble_models(model_dir, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    ensemble_models = {}\n",
    "    for fname in os.listdir(model_dir):\n",
    "        if fname.startswith(\"model2-\") and fname.endswith(\".pt\"):\n",
    "            try:\n",
    "                parts = fname[len(\"model2-\"):-3].split(\"_\")\n",
    "                n, k, m = map(int, parts)\n",
    "                path = os.path.join(model_dir, fname)\n",
    "                checkpoint = torch.load(path, map_location=device)\n",
    "                config = checkpoint['config']\n",
    "                model = TransformerRegression(\n",
    "                    token_dim=config['token_dim'],\n",
    "                    d_model=config['d_model'],\n",
    "                    nhead=config['nhead'],\n",
    "                    num_layers=config['num_layers'],\n",
    "                    dim_feedforward=config['dim_feedforward'],\n",
    "                    dropout=config['dropout'],\n",
    "                    n=config['n'], k=config['k'], m=config['m']\n",
    "                ).to(device)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                model.eval()\n",
    "                ensemble_models[(n, k, m)] = model\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {fname}: {e}\")\n",
    "    return ensemble_models\n",
    "\n",
    "def run_ensemble_predictions(df_test, ensemble_models, batch_size=64):\n",
    "    from collections import defaultdict\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Store results\n",
    "    prediction_results = []\n",
    "\n",
    "    # Group by n, k, m\n",
    "    for (n, k, m), group in df_test.groupby([\"n\", \"k\", \"m\"]):\n",
    "        model = ensemble_models.get((n, k, m))\n",
    "        if model is None:\n",
    "            print(f\"No model for (n={n}, k={k}, m={m}) â€” skipping\")\n",
    "            continue\n",
    "\n",
    "        dataset = RowColTokenDataset(group.reset_index(drop=True), n=n, k=k)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for tokens, _ in loader:\n",
    "                tokens = tokens.to(device)\n",
    "                pred = model(tokens).squeeze(1)\n",
    "                preds.extend(pred.cpu().numpy().tolist())\n",
    "\n",
    "        result_df = group.copy()\n",
    "        result_df[\"prediction\"] = preds\n",
    "        prediction_results.append(result_df)\n",
    "\n",
    "    if prediction_results:\n",
    "        return pd.concat(prediction_results, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_dataframe(n, k, m, P_list):\n",
    "    \"\"\"\n",
    "    Converts a list of P matrices into a DataFrame compatible with RowColTokenDataset.\n",
    "\n",
    "    Parameters:\n",
    "        n (int): total number of columns in original matrix\n",
    "        k (int): number of rows in each P matrix\n",
    "        m (int or list[int]): the m value(s), scalar or one per row\n",
    "        P_list (list or np.ndarray): one or more numpy matrices of shape (k, n-k)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns: 'n', 'k', 'm', 'P'\n",
    "    \"\"\"\n",
    "    if isinstance(P_list, np.ndarray) and P_list.ndim == 2:\n",
    "        P_list = [P_list]  # single matrix case\n",
    "\n",
    "    if not isinstance(P_list, list):\n",
    "        raise ValueError(\"P_list must be a list of numpy arrays\")\n",
    "\n",
    "    for i, P in enumerate(P_list):\n",
    "        if P.shape != (k, n - k):\n",
    "            raise ValueError(f\"P[{i}] has shape {P.shape}, expected ({k}, {n - k})\")\n",
    "\n",
    "    # Broadcast m if scalar\n",
    "    m_values = [m] * len(P_list) if isinstance(m, int) else m\n",
    "    if len(m_values) != len(P_list):\n",
    "        raise ValueError(\"Length of m must match number of P matrices\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"n\": [n] * len(P_list),\n",
    "        \"k\": [k] * len(P_list),\n",
    "        \"m\": m_values,\n",
    "        \"P\": [p.tolist() for p in P_list]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "def norm(x):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    return ((x + 100) / 200) * 2 - 1\n",
    "\n",
    "n, k, m = 9, 4, 3\n",
    "ensemble_models = load_ensemble_models(\"./\")\n",
    "P_raw = df[(df['n'] == n) & (df['k'] == k) & (df['m'] == m)].head(1)['P'].values[0]\n",
    "P_norm = norm(P_raw).reshape(k, n - k)\n",
    "df_test = build_test_dataframe(n=n, k=k, m=m, P_list=[P_norm])\n",
    "ensemble_output_df = run_ensemble_predictions(df_test, ensemble_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n  k  m                                                  P  prediction\n",
      "0  9  4  3  [[0.9114111661911011, -0.15260308980941772, -0...  272.356445\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_output_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
